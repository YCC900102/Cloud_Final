{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Total Reward: -3.0, Epsilon: 0.200\n",
      "Episode: 1, Total Reward: -8, Epsilon: 0.199\n",
      "Episode: 2, Total Reward: -10, Epsilon: 0.198\n",
      "Episode: 3, Total Reward: 3.5, Epsilon: 0.197\n",
      "Episode: 4, Total Reward: -7, Epsilon: 0.196\n",
      "Episode: 5, Total Reward: 10.0, Epsilon: 0.195\n",
      "Episode: 6, Total Reward: -4, Epsilon: 0.194\n",
      "Episode: 7, Total Reward: -1.5, Epsilon: 0.193\n",
      "Episode: 8, Total Reward: -6, Epsilon: 0.192\n",
      "Episode: 9, Total Reward: 1.9000000000000004, Epsilon: 0.191\n",
      "Episode: 10, Total Reward: 11.5, Epsilon: 0.190\n",
      "Episode: 11, Total Reward: -10, Epsilon: 0.189\n",
      "Episode: 12, Total Reward: -8, Epsilon: 0.188\n",
      "Episode: 13, Total Reward: 3.5, Epsilon: 0.187\n",
      "Episode: 14, Total Reward: 10, Epsilon: 0.186\n",
      "Episode: 15, Total Reward: 1, Epsilon: 0.186\n",
      "Episode: 16, Total Reward: 17, Epsilon: 0.185\n",
      "Episode: 17, Total Reward: -6.1, Epsilon: 0.184\n",
      "Episode: 18, Total Reward: 0.0, Epsilon: 0.183\n",
      "Episode: 19, Total Reward: -2, Epsilon: 0.182\n",
      "Episode: 20, Total Reward: 10, Epsilon: 0.181\n",
      "Episode: 21, Total Reward: -6, Epsilon: 0.180\n",
      "Episode: 22, Total Reward: -2, Epsilon: 0.179\n",
      "Episode: 23, Total Reward: -4.1, Epsilon: 0.178\n",
      "Episode: 24, Total Reward: -10, Epsilon: 0.177\n",
      "Episode: 25, Total Reward: -8.1, Epsilon: 0.176\n",
      "Episode: 26, Total Reward: -7.0, Epsilon: 0.176\n",
      "Episode: 27, Total Reward: 1.4000000000000004, Epsilon: 0.175\n",
      "Episode: 28, Total Reward: -8, Epsilon: 0.174\n",
      "Episode: 29, Total Reward: -7.1, Epsilon: 0.173\n",
      "Episode: 30, Total Reward: 5.9, Epsilon: 0.172\n",
      "Episode: 31, Total Reward: -1.0999999999999996, Epsilon: 0.171\n",
      "Episode: 32, Total Reward: -6.1, Epsilon: 0.170\n",
      "Episode: 33, Total Reward: -4, Epsilon: 0.170\n",
      "Episode: 34, Total Reward: 18.9, Epsilon: 0.169\n",
      "Episode: 35, Total Reward: 25, Epsilon: 0.168\n",
      "Episode: 36, Total Reward: -10, Epsilon: 0.167\n",
      "Episode: 37, Total Reward: 27.0, Epsilon: 0.166\n",
      "Episode: 38, Total Reward: -6.6, Epsilon: 0.165\n",
      "Episode: 39, Total Reward: 16.4, Epsilon: 0.164\n",
      "Episode: 40, Total Reward: -7.5, Epsilon: 0.164\n",
      "Episode: 41, Total Reward: 71.9, Epsilon: 0.163\n",
      "Episode: 42, Total Reward: 28.9, Epsilon: 0.162\n",
      "Episode: 43, Total Reward: -6, Epsilon: 0.161\n",
      "Episode: 44, Total Reward: 23.9, Epsilon: 0.160\n",
      "Episode: 45, Total Reward: 11, Epsilon: 0.160\n",
      "Episode: 46, Total Reward: 25, Epsilon: 0.159\n",
      "Episode: 47, Total Reward: -10, Epsilon: 0.158\n",
      "Episode: 48, Total Reward: -8, Epsilon: 0.157\n",
      "Episode: 49, Total Reward: 6, Epsilon: 0.156\n",
      "Episode: 50, Total Reward: -8, Epsilon: 0.156\n",
      "Episode: 51, Total Reward: 1, Epsilon: 0.155\n",
      "Episode: 52, Total Reward: -4, Epsilon: 0.154\n",
      "Episode: 53, Total Reward: 6.5, Epsilon: 0.153\n",
      "Episode: 54, Total Reward: 22.5, Epsilon: 0.153\n",
      "Episode: 55, Total Reward: 7.899999999999999, Epsilon: 0.152\n",
      "Episode: 56, Total Reward: -1, Epsilon: 0.151\n",
      "Episode: 57, Total Reward: -1, Epsilon: 0.150\n",
      "Episode: 58, Total Reward: 1.4000000000000004, Epsilon: 0.150\n",
      "Episode: 59, Total Reward: -6, Epsilon: 0.149\n",
      "Episode: 60, Total Reward: 6, Epsilon: 0.148\n",
      "Episode: 61, Total Reward: -7.5, Epsilon: 0.147\n",
      "Episode: 62, Total Reward: 2, Epsilon: 0.147\n",
      "Episode: 63, Total Reward: 10.5, Epsilon: 0.146\n",
      "Episode: 64, Total Reward: 12, Epsilon: 0.145\n",
      "Episode: 65, Total Reward: 16, Epsilon: 0.144\n",
      "Episode: 66, Total Reward: 18.9, Epsilon: 0.144\n",
      "Episode: 67, Total Reward: 14, Epsilon: 0.143\n",
      "Episode: 68, Total Reward: -10, Epsilon: 0.142\n",
      "Episode: 69, Total Reward: 24.0, Epsilon: 0.142\n",
      "Episode: 70, Total Reward: 10.899999999999999, Epsilon: 0.141\n",
      "Episode: 71, Total Reward: 7, Epsilon: 0.140\n",
      "Episode: 72, Total Reward: -3.5, Epsilon: 0.139\n",
      "Episode: 73, Total Reward: -3.5999999999999996, Epsilon: 0.139\n",
      "Episode: 74, Total Reward: -3.0999999999999996, Epsilon: 0.138\n",
      "Episode: 75, Total Reward: -8, Epsilon: 0.137\n",
      "Episode: 76, Total Reward: 2.9000000000000004, Epsilon: 0.137\n",
      "Episode: 77, Total Reward: 0, Epsilon: 0.136\n",
      "Episode: 78, Total Reward: 11.600000000000001, Epsilon: 0.135\n",
      "Episode: 79, Total Reward: 9, Epsilon: 0.135\n",
      "Episode: 80, Total Reward: -4.1, Epsilon: 0.134\n",
      "Episode: 81, Total Reward: 40.9, Epsilon: 0.133\n",
      "Episode: 82, Total Reward: 51.5, Epsilon: 0.133\n",
      "Episode: 83, Total Reward: 2.5, Epsilon: 0.132\n",
      "Episode: 84, Total Reward: 24.299999999999997, Epsilon: 0.131\n",
      "Episode: 85, Total Reward: -10, Epsilon: 0.131\n",
      "Episode: 86, Total Reward: 0.0, Epsilon: 0.130\n",
      "Episode: 87, Total Reward: 8, Epsilon: 0.129\n",
      "Episode: 88, Total Reward: -8, Epsilon: 0.129\n",
      "Episode: 89, Total Reward: -7.1, Epsilon: 0.128\n",
      "Episode: 90, Total Reward: 18.4, Epsilon: 0.127\n",
      "Episode: 91, Total Reward: 31.799999999999997, Epsilon: 0.127\n",
      "Episode: 92, Total Reward: -2.0999999999999996, Epsilon: 0.126\n",
      "Episode: 93, Total Reward: 13.899999999999999, Epsilon: 0.125\n",
      "Episode: 94, Total Reward: -8, Epsilon: 0.125\n",
      "Episode: 95, Total Reward: 2.6999999999999993, Epsilon: 0.124\n",
      "Episode: 96, Total Reward: 10.899999999999999, Epsilon: 0.124\n",
      "Episode: 97, Total Reward: -8, Epsilon: 0.123\n",
      "Episode: 98, Total Reward: -1.0999999999999996, Epsilon: 0.122\n",
      "Episode: 99, Total Reward: 0.8000000000000007, Epsilon: 0.122\n",
      "Episode: 100, Total Reward: 2, Epsilon: 0.121\n",
      "Episode: 101, Total Reward: 37.9, Epsilon: 0.121\n",
      "Episode: 102, Total Reward: -10, Epsilon: 0.120\n",
      "Episode: 103, Total Reward: 15.899999999999999, Epsilon: 0.119\n",
      "Episode: 104, Total Reward: -8, Epsilon: 0.119\n",
      "Episode: 105, Total Reward: 106.0, Epsilon: 0.118\n",
      "Episode: 106, Total Reward: -3.6999999999999993, Epsilon: 0.118\n",
      "Episode: 107, Total Reward: 18.8, Epsilon: 0.117\n",
      "Episode: 108, Total Reward: -10, Epsilon: 0.116\n",
      "Episode: 109, Total Reward: -7, Epsilon: 0.116\n",
      "Episode: 110, Total Reward: 1.9000000000000004, Epsilon: 0.115\n",
      "Episode: 111, Total Reward: 216.8, Epsilon: 0.115\n",
      "Episode: 112, Total Reward: -8, Epsilon: 0.114\n",
      "Episode: 113, Total Reward: -4, Epsilon: 0.114\n",
      "Episode: 114, Total Reward: -8, Epsilon: 0.113\n",
      "Episode: 115, Total Reward: -6.1, Epsilon: 0.112\n",
      "Episode: 116, Total Reward: 4, Epsilon: 0.112\n",
      "Episode: 117, Total Reward: -8, Epsilon: 0.111\n",
      "Episode: 118, Total Reward: -10, Epsilon: 0.111\n",
      "Episode: 119, Total Reward: 0, Epsilon: 0.110\n",
      "Episode: 120, Total Reward: -10, Epsilon: 0.110\n",
      "Episode: 121, Total Reward: 25, Epsilon: 0.109\n",
      "Episode: 122, Total Reward: 7.899999999999999, Epsilon: 0.109\n",
      "Episode: 123, Total Reward: -10, Epsilon: 0.108\n",
      "Episode: 124, Total Reward: -8.1, Epsilon: 0.107\n",
      "Episode: 125, Total Reward: -10, Epsilon: 0.107\n",
      "Episode: 126, Total Reward: -10, Epsilon: 0.106\n",
      "Episode: 127, Total Reward: -7.5, Epsilon: 0.106\n",
      "Episode: 128, Total Reward: -2.4000000000000004, Epsilon: 0.105\n",
      "Episode: 129, Total Reward: 5.5, Epsilon: 0.105\n",
      "Episode: 130, Total Reward: -8, Epsilon: 0.104\n",
      "Episode: 131, Total Reward: -2, Epsilon: 0.104\n",
      "Episode: 132, Total Reward: 103.7, Epsilon: 0.103\n",
      "Episode: 133, Total Reward: -10, Epsilon: 0.103\n",
      "Episode: 134, Total Reward: -2, Epsilon: 0.102\n",
      "Episode: 135, Total Reward: 40.3, Epsilon: 0.102\n",
      "Episode: 136, Total Reward: -8.1, Epsilon: 0.101\n",
      "Episode: 137, Total Reward: 4.4, Epsilon: 0.101\n",
      "Episode: 138, Total Reward: -4.1, Epsilon: 0.100\n",
      "Episode: 139, Total Reward: -3.0999999999999996, Epsilon: 0.100\n",
      "Episode: 140, Total Reward: 0, Epsilon: 0.099\n",
      "Episode: 141, Total Reward: 2.5, Epsilon: 0.099\n",
      "Episode: 142, Total Reward: -1, Epsilon: 0.098\n",
      "Episode: 143, Total Reward: 1.9000000000000004, Epsilon: 0.098\n",
      "Episode: 144, Total Reward: 46.8, Epsilon: 0.097\n",
      "Episode: 145, Total Reward: 30.9, Epsilon: 0.097\n",
      "Episode: 146, Total Reward: -3, Epsilon: 0.096\n",
      "Episode: 147, Total Reward: 10, Epsilon: 0.096\n",
      "Episode: 148, Total Reward: -8.2, Epsilon: 0.095\n",
      "Episode: 149, Total Reward: 8.899999999999999, Epsilon: 0.095\n",
      "Episode: 150, Total Reward: -4, Epsilon: 0.094\n",
      "Episode: 151, Total Reward: 2, Epsilon: 0.094\n",
      "Episode: 152, Total Reward: -8, Epsilon: 0.093\n",
      "Episode: 153, Total Reward: 25.599999999999994, Epsilon: 0.093\n",
      "Episode: 154, Total Reward: -2, Epsilon: 0.092\n",
      "Episode: 155, Total Reward: -1, Epsilon: 0.092\n",
      "Episode: 156, Total Reward: 3.8000000000000007, Epsilon: 0.092\n",
      "Episode: 157, Total Reward: -7.5, Epsilon: 0.091\n",
      "Episode: 158, Total Reward: 42.9, Epsilon: 0.091\n",
      "Episode: 159, Total Reward: 19.9, Epsilon: 0.090\n",
      "Episode: 160, Total Reward: 20.9, Epsilon: 0.090\n",
      "Episode: 161, Total Reward: -6, Epsilon: 0.089\n",
      "Episode: 162, Total Reward: -4.1, Epsilon: 0.089\n",
      "Episode: 163, Total Reward: 1, Epsilon: 0.088\n",
      "Episode: 164, Total Reward: -4, Epsilon: 0.088\n",
      "Episode: 165, Total Reward: -4.2, Epsilon: 0.087\n",
      "Episode: 166, Total Reward: 35.099999999999994, Epsilon: 0.087\n",
      "Episode: 167, Total Reward: -2, Epsilon: 0.087\n",
      "Episode: 168, Total Reward: 45.3, Epsilon: 0.086\n",
      "Episode: 169, Total Reward: -6, Epsilon: 0.086\n",
      "Episode: 170, Total Reward: 1.9000000000000004, Epsilon: 0.085\n",
      "Episode: 171, Total Reward: -8.1, Epsilon: 0.085\n",
      "Episode: 172, Total Reward: -4.7, Epsilon: 0.084\n",
      "Episode: 173, Total Reward: -1.0999999999999996, Epsilon: 0.084\n",
      "Episode: 174, Total Reward: -7.1, Epsilon: 0.084\n",
      "Episode: 175, Total Reward: 12.399999999999999, Epsilon: 0.083\n",
      "Episode: 176, Total Reward: 8.8, Epsilon: 0.083\n",
      "Episode: 177, Total Reward: -10, Epsilon: 0.082\n",
      "Episode: 178, Total Reward: 9.899999999999999, Epsilon: 0.082\n",
      "Episode: 179, Total Reward: 19.799999999999997, Epsilon: 0.082\n",
      "Episode: 180, Total Reward: 66.19999999999999, Epsilon: 0.081\n",
      "Episode: 181, Total Reward: -10, Epsilon: 0.081\n",
      "Episode: 182, Total Reward: 23.9, Epsilon: 0.080\n",
      "Episode: 183, Total Reward: -8.1, Epsilon: 0.080\n",
      "Episode: 184, Total Reward: 6.899999999999999, Epsilon: 0.080\n",
      "Episode: 185, Total Reward: 0, Epsilon: 0.079\n",
      "Episode: 186, Total Reward: -8, Epsilon: 0.079\n",
      "Episode: 187, Total Reward: 1.9000000000000004, Epsilon: 0.078\n",
      "Episode: 188, Total Reward: -4.1, Epsilon: 0.078\n",
      "Episode: 189, Total Reward: 18.299999999999997, Epsilon: 0.078\n",
      "Episode: 190, Total Reward: 9.5, Epsilon: 0.077\n",
      "Episode: 191, Total Reward: 38.699999999999996, Epsilon: 0.077\n",
      "Episode: 192, Total Reward: -4.2, Epsilon: 0.076\n",
      "Episode: 193, Total Reward: 8, Epsilon: 0.076\n",
      "Episode: 194, Total Reward: -4, Epsilon: 0.076\n",
      "Episode: 195, Total Reward: -8.1, Epsilon: 0.075\n",
      "Episode: 196, Total Reward: 14, Epsilon: 0.075\n",
      "Episode: 197, Total Reward: 0, Epsilon: 0.075\n",
      "Episode: 198, Total Reward: -8, Epsilon: 0.074\n",
      "Episode: 199, Total Reward: 2, Epsilon: 0.074\n",
      "Episode: 200, Total Reward: 27, Epsilon: 0.073\n",
      "Episode: 201, Total Reward: -6, Epsilon: 0.073\n",
      "Episode: 202, Total Reward: 1.9000000000000004, Epsilon: 0.073\n",
      "Episode: 203, Total Reward: -8, Epsilon: 0.072\n",
      "Episode: 204, Total Reward: -5.1, Epsilon: 0.072\n",
      "Episode: 205, Total Reward: 9, Epsilon: 0.072\n",
      "Episode: 206, Total Reward: 4.9, Epsilon: 0.071\n",
      "Episode: 207, Total Reward: -5, Epsilon: 0.071\n",
      "Episode: 208, Total Reward: -10, Epsilon: 0.071\n",
      "Episode: 209, Total Reward: 11, Epsilon: 0.070\n",
      "Episode: 210, Total Reward: -1.5, Epsilon: 0.070\n",
      "Episode: 211, Total Reward: -4.1, Epsilon: 0.069\n",
      "Episode: 212, Total Reward: 5, Epsilon: 0.069\n",
      "Episode: 213, Total Reward: -8, Epsilon: 0.069\n",
      "Episode: 214, Total Reward: 8.399999999999999, Epsilon: 0.068\n",
      "Episode: 215, Total Reward: -10, Epsilon: 0.068\n",
      "Episode: 216, Total Reward: 0.3000000000000007, Epsilon: 0.068\n",
      "Episode: 217, Total Reward: -8, Epsilon: 0.067\n",
      "Episode: 218, Total Reward: -6, Epsilon: 0.067\n",
      "Episode: 219, Total Reward: 15, Epsilon: 0.067\n",
      "Episode: 220, Total Reward: -7, Epsilon: 0.066\n",
      "Episode: 221, Total Reward: -8, Epsilon: 0.066\n",
      "Episode: 222, Total Reward: -2, Epsilon: 0.066\n",
      "Episode: 223, Total Reward: 12, Epsilon: 0.065\n",
      "Episode: 224, Total Reward: 19.9, Epsilon: 0.065\n",
      "Episode: 225, Total Reward: -10, Epsilon: 0.065\n",
      "Episode: 226, Total Reward: -8, Epsilon: 0.064\n",
      "Episode: 227, Total Reward: 31, Epsilon: 0.064\n",
      "Episode: 228, Total Reward: -6, Epsilon: 0.064\n",
      "Episode: 229, Total Reward: 21.3, Epsilon: 0.063\n",
      "Episode: 230, Total Reward: -6.1, Epsilon: 0.063\n",
      "Episode: 231, Total Reward: -10, Epsilon: 0.063\n",
      "Episode: 232, Total Reward: -4, Epsilon: 0.063\n",
      "Episode: 233, Total Reward: 12.899999999999999, Epsilon: 0.062\n",
      "Episode: 234, Total Reward: 24.799999999999997, Epsilon: 0.062\n",
      "Episode: 235, Total Reward: 3.9000000000000004, Epsilon: 0.062\n",
      "Episode: 236, Total Reward: 22.4, Epsilon: 0.061\n",
      "Episode: 237, Total Reward: 9, Epsilon: 0.061\n",
      "Episode: 238, Total Reward: 170.8, Epsilon: 0.061\n",
      "Episode: 239, Total Reward: 35.9, Epsilon: 0.060\n",
      "Episode: 240, Total Reward: 37.9, Epsilon: 0.060\n",
      "Episode: 241, Total Reward: 2, Epsilon: 0.060\n",
      "Episode: 242, Total Reward: 7, Epsilon: 0.059\n",
      "Episode: 243, Total Reward: -2.0999999999999996, Epsilon: 0.059\n",
      "Episode: 244, Total Reward: 2, Epsilon: 0.059\n",
      "Episode: 245, Total Reward: -1.5, Epsilon: 0.059\n",
      "Episode: 246, Total Reward: -6, Epsilon: 0.058\n",
      "Episode: 247, Total Reward: -10, Epsilon: 0.058\n",
      "Episode: 248, Total Reward: -10, Epsilon: 0.058\n",
      "Episode: 249, Total Reward: 2.9000000000000004, Epsilon: 0.057\n",
      "Episode: 250, Total Reward: 8.899999999999999, Epsilon: 0.057\n",
      "Episode: 251, Total Reward: 16.6, Epsilon: 0.057\n",
      "Episode: 252, Total Reward: -10, Epsilon: 0.057\n",
      "Episode: 253, Total Reward: -1, Epsilon: 0.056\n",
      "Episode: 254, Total Reward: -5.1, Epsilon: 0.056\n",
      "Episode: 255, Total Reward: -3.0999999999999996, Epsilon: 0.056\n",
      "Episode: 256, Total Reward: 7.899999999999999, Epsilon: 0.055\n",
      "Episode: 257, Total Reward: 14.3, Epsilon: 0.055\n",
      "Episode: 258, Total Reward: -10, Epsilon: 0.055\n",
      "Episode: 259, Total Reward: 3.8000000000000007, Epsilon: 0.055\n",
      "Episode: 260, Total Reward: 11, Epsilon: 0.054\n",
      "Episode: 261, Total Reward: -10, Epsilon: 0.054\n",
      "Episode: 262, Total Reward: -2, Epsilon: 0.054\n",
      "Episode: 263, Total Reward: 2, Epsilon: 0.054\n",
      "Episode: 264, Total Reward: -9.5, Epsilon: 0.053\n",
      "Episode: 265, Total Reward: 25, Epsilon: 0.053\n",
      "Episode: 266, Total Reward: 30.799999999999997, Epsilon: 0.053\n",
      "Episode: 267, Total Reward: 0, Epsilon: 0.052\n",
      "Episode: 268, Total Reward: 34.5, Epsilon: 0.052\n",
      "Episode: 269, Total Reward: -6.1, Epsilon: 0.052\n",
      "Episode: 270, Total Reward: -8.1, Epsilon: 0.052\n",
      "Episode: 271, Total Reward: 5, Epsilon: 0.051\n",
      "Episode: 272, Total Reward: 83.9, Epsilon: 0.051\n",
      "Episode: 273, Total Reward: 7, Epsilon: 0.051\n",
      "Episode: 274, Total Reward: -1.5, Epsilon: 0.051\n",
      "Episode: 275, Total Reward: -2, Epsilon: 0.050\n",
      "Episode: 276, Total Reward: 0.3000000000000007, Epsilon: 0.050\n",
      "Episode: 277, Total Reward: 0.1999999999999993, Epsilon: 0.050\n",
      "Episode: 278, Total Reward: 0.9000000000000004, Epsilon: 0.050\n",
      "Episode: 279, Total Reward: 8.899999999999999, Epsilon: 0.049\n",
      "Episode: 280, Total Reward: -10, Epsilon: 0.049\n",
      "Episode: 281, Total Reward: -10, Epsilon: 0.049\n",
      "Episode: 282, Total Reward: -10, Epsilon: 0.049\n",
      "Episode: 283, Total Reward: 25.699999999999996, Epsilon: 0.048\n",
      "Episode: 284, Total Reward: -8, Epsilon: 0.048\n",
      "Episode: 285, Total Reward: -0.09999999999999964, Epsilon: 0.048\n",
      "Episode: 286, Total Reward: -3, Epsilon: 0.048\n",
      "Episode: 287, Total Reward: -3.0999999999999996, Epsilon: 0.047\n",
      "Episode: 288, Total Reward: 9.899999999999999, Epsilon: 0.047\n",
      "Episode: 289, Total Reward: 11.899999999999999, Epsilon: 0.047\n",
      "Episode: 290, Total Reward: 13.899999999999999, Epsilon: 0.047\n",
      "Episode: 291, Total Reward: -6.1, Epsilon: 0.047\n",
      "Episode: 292, Total Reward: 4, Epsilon: 0.046\n",
      "Episode: 293, Total Reward: 13.3, Epsilon: 0.046\n",
      "Episode: 294, Total Reward: -0.3000000000000007, Epsilon: 0.046\n",
      "Episode: 295, Total Reward: 14.899999999999999, Epsilon: 0.046\n",
      "Episode: 296, Total Reward: 17.099999999999998, Epsilon: 0.045\n",
      "Episode: 297, Total Reward: 115.8, Epsilon: 0.045\n",
      "Episode: 298, Total Reward: 6, Epsilon: 0.045\n",
      "Episode: 299, Total Reward: -5.1, Epsilon: 0.045\n",
      "Episode: 300, Total Reward: -8.1, Epsilon: 0.044\n",
      "Episode: 301, Total Reward: -4, Epsilon: 0.044\n",
      "Episode: 302, Total Reward: -10, Epsilon: 0.044\n",
      "Episode: 303, Total Reward: -7, Epsilon: 0.044\n",
      "Episode: 304, Total Reward: -8, Epsilon: 0.044\n",
      "Episode: 305, Total Reward: 11, Epsilon: 0.043\n",
      "Episode: 306, Total Reward: 37.5, Epsilon: 0.043\n",
      "Episode: 307, Total Reward: -10, Epsilon: 0.043\n",
      "Episode: 308, Total Reward: 20.0, Epsilon: 0.043\n",
      "Episode: 309, Total Reward: 0, Epsilon: 0.042\n",
      "Episode: 310, Total Reward: 16.4, Epsilon: 0.042\n",
      "Episode: 311, Total Reward: 1, Epsilon: 0.042\n",
      "Episode: 312, Total Reward: 0, Epsilon: 0.042\n",
      "Episode: 313, Total Reward: 6, Epsilon: 0.042\n",
      "Episode: 314, Total Reward: -2.0999999999999996, Epsilon: 0.041\n",
      "Episode: 315, Total Reward: 2.5, Epsilon: 0.041\n",
      "Episode: 316, Total Reward: 60.400000000000006, Epsilon: 0.041\n",
      "Episode: 317, Total Reward: 15.899999999999999, Epsilon: 0.041\n",
      "Episode: 318, Total Reward: 1.9000000000000004, Epsilon: 0.041\n",
      "Episode: 319, Total Reward: -8, Epsilon: 0.040\n",
      "Episode: 320, Total Reward: 13, Epsilon: 0.040\n",
      "Episode: 321, Total Reward: 15.399999999999999, Epsilon: 0.040\n",
      "Episode: 322, Total Reward: 1.0, Epsilon: 0.040\n",
      "Episode: 323, Total Reward: 1.3000000000000007, Epsilon: 0.040\n",
      "Episode: 324, Total Reward: -4, Epsilon: 0.039\n",
      "Episode: 325, Total Reward: 4, Epsilon: 0.039\n",
      "Episode: 326, Total Reward: 6.699999999999999, Epsilon: 0.039\n",
      "Episode: 327, Total Reward: 6.700000000000003, Epsilon: 0.039\n",
      "Episode: 328, Total Reward: -3, Epsilon: 0.039\n",
      "Episode: 329, Total Reward: -10, Epsilon: 0.038\n",
      "Episode: 330, Total Reward: 8.5, Epsilon: 0.038\n",
      "Episode: 331, Total Reward: -2, Epsilon: 0.038\n",
      "Episode: 332, Total Reward: 3, Epsilon: 0.038\n",
      "Episode: 333, Total Reward: 10, Epsilon: 0.038\n",
      "Episode: 334, Total Reward: 3.8000000000000007, Epsilon: 0.037\n",
      "Episode: 335, Total Reward: -8, Epsilon: 0.037\n",
      "Episode: 336, Total Reward: -5.1, Epsilon: 0.037\n",
      "Episode: 337, Total Reward: -5, Epsilon: 0.037\n",
      "Episode: 338, Total Reward: -6, Epsilon: 0.037\n",
      "Episode: 339, Total Reward: -9.7, Epsilon: 0.037\n",
      "Episode: 340, Total Reward: 45.0, Epsilon: 0.036\n",
      "Episode: 341, Total Reward: 29.9, Epsilon: 0.036\n",
      "Episode: 342, Total Reward: 14.899999999999999, Epsilon: 0.036\n",
      "Episode: 343, Total Reward: 2.9000000000000004, Epsilon: 0.036\n",
      "Episode: 344, Total Reward: 8.2, Epsilon: 0.036\n",
      "Episode: 345, Total Reward: 2.8000000000000007, Epsilon: 0.035\n",
      "Episode: 346, Total Reward: 52.699999999999996, Epsilon: 0.035\n",
      "Episode: 347, Total Reward: 9.600000000000001, Epsilon: 0.035\n",
      "Episode: 348, Total Reward: 5.9, Epsilon: 0.035\n",
      "Episode: 349, Total Reward: 5.4, Epsilon: 0.035\n",
      "Episode: 350, Total Reward: 0.20000000000000107, Epsilon: 0.035\n",
      "Episode: 351, Total Reward: -7.1, Epsilon: 0.034\n",
      "Episode: 352, Total Reward: -4.299999999999999, Epsilon: 0.034\n",
      "Episode: 353, Total Reward: -10.1, Epsilon: 0.034\n",
      "Episode: 354, Total Reward: -1.3000000000000007, Epsilon: 0.034\n",
      "Episode: 355, Total Reward: -7.6, Epsilon: 0.034\n",
      "Episode: 356, Total Reward: -1.0999999999999996, Epsilon: 0.034\n",
      "Episode: 357, Total Reward: 28.299999999999997, Epsilon: 0.033\n",
      "Episode: 358, Total Reward: -5, Epsilon: 0.033\n",
      "Episode: 359, Total Reward: -4, Epsilon: 0.033\n",
      "Episode: 360, Total Reward: -6.1, Epsilon: 0.033\n",
      "Episode: 361, Total Reward: 3.9000000000000004, Epsilon: 0.033\n",
      "Episode: 362, Total Reward: -3.0999999999999996, Epsilon: 0.033\n",
      "Episode: 363, Total Reward: -10, Epsilon: 0.032\n",
      "Episode: 364, Total Reward: -10, Epsilon: 0.032\n",
      "Episode: 365, Total Reward: 56.19999999999999, Epsilon: 0.032\n",
      "Episode: 366, Total Reward: 1, Epsilon: 0.032\n",
      "Episode: 367, Total Reward: -10, Epsilon: 0.032\n",
      "Episode: 368, Total Reward: -8, Epsilon: 0.032\n",
      "Episode: 369, Total Reward: 15.600000000000001, Epsilon: 0.031\n",
      "Episode: 370, Total Reward: 7.700000000000003, Epsilon: 0.031\n",
      "Episode: 371, Total Reward: -10.1, Epsilon: 0.031\n",
      "Episode: 372, Total Reward: -2.2, Epsilon: 0.031\n",
      "Episode: 373, Total Reward: -6.1, Epsilon: 0.031\n",
      "Episode: 374, Total Reward: -3.5999999999999996, Epsilon: 0.031\n",
      "Episode: 375, Total Reward: -6, Epsilon: 0.031\n",
      "Episode: 376, Total Reward: 4.9, Epsilon: 0.030\n",
      "Episode: 377, Total Reward: 23.9, Epsilon: 0.030\n",
      "Episode: 378, Total Reward: -6, Epsilon: 0.030\n",
      "Episode: 379, Total Reward: -10, Epsilon: 0.030\n",
      "Episode: 380, Total Reward: 89.30000000000001, Epsilon: 0.030\n",
      "Episode: 381, Total Reward: 26, Epsilon: 0.030\n",
      "Episode: 382, Total Reward: 7.899999999999999, Epsilon: 0.029\n",
      "Episode: 383, Total Reward: 14.899999999999999, Epsilon: 0.029\n",
      "Episode: 384, Total Reward: -10, Epsilon: 0.029\n",
      "Episode: 385, Total Reward: -10, Epsilon: 0.029\n",
      "Episode: 386, Total Reward: -10, Epsilon: 0.029\n",
      "Episode: 387, Total Reward: -8.1, Epsilon: 0.029\n",
      "Episode: 388, Total Reward: -8, Epsilon: 0.029\n",
      "Episode: 389, Total Reward: -0.1999999999999993, Epsilon: 0.028\n",
      "Episode: 390, Total Reward: -10, Epsilon: 0.028\n",
      "Episode: 391, Total Reward: 8, Epsilon: 0.028\n",
      "Episode: 392, Total Reward: 0.0, Epsilon: 0.028\n",
      "Episode: 393, Total Reward: -4.1, Epsilon: 0.028\n",
      "Episode: 394, Total Reward: -6.2, Epsilon: 0.028\n",
      "Episode: 395, Total Reward: -0.5999999999999996, Epsilon: 0.028\n",
      "Episode: 396, Total Reward: -7, Epsilon: 0.027\n",
      "Episode: 397, Total Reward: -10, Epsilon: 0.027\n",
      "Episode: 398, Total Reward: 16.5, Epsilon: 0.027\n",
      "Episode: 399, Total Reward: 82.8, Epsilon: 0.027\n",
      "Episode: 400, Total Reward: -10, Epsilon: 0.027\n",
      "Episode: 401, Total Reward: 0, Epsilon: 0.027\n",
      "Episode: 402, Total Reward: 2, Epsilon: 0.027\n",
      "Episode: 403, Total Reward: -10, Epsilon: 0.027\n",
      "Episode: 404, Total Reward: -10, Epsilon: 0.026\n",
      "Episode: 405, Total Reward: 14, Epsilon: 0.026\n",
      "Episode: 406, Total Reward: 3.9000000000000004, Epsilon: 0.026\n",
      "Episode: 407, Total Reward: 0.6000000000000014, Epsilon: 0.026\n",
      "Episode: 408, Total Reward: -8, Epsilon: 0.026\n",
      "Episode: 409, Total Reward: 6.700000000000003, Epsilon: 0.026\n",
      "Episode: 410, Total Reward: -4, Epsilon: 0.026\n",
      "Episode: 411, Total Reward: -6.1, Epsilon: 0.025\n",
      "Episode: 412, Total Reward: -7.1, Epsilon: 0.025\n",
      "Episode: 413, Total Reward: 132.5, Epsilon: 0.025\n",
      "Episode: 414, Total Reward: 10.700000000000003, Epsilon: 0.025\n",
      "Episode: 415, Total Reward: -10.1, Epsilon: 0.025\n",
      "Episode: 416, Total Reward: -10.1, Epsilon: 0.025\n",
      "Episode: 417, Total Reward: -2.2, Epsilon: 0.025\n",
      "Episode: 418, Total Reward: 7, Epsilon: 0.025\n",
      "Episode: 419, Total Reward: -5, Epsilon: 0.024\n",
      "Episode: 420, Total Reward: 17.799999999999997, Epsilon: 0.024\n",
      "Episode: 421, Total Reward: -8.1, Epsilon: 0.024\n",
      "Episode: 422, Total Reward: -6, Epsilon: 0.024\n",
      "Episode: 423, Total Reward: 23.799999999999997, Epsilon: 0.024\n",
      "Episode: 424, Total Reward: -10, Epsilon: 0.024\n",
      "Episode: 425, Total Reward: -5.1, Epsilon: 0.024\n",
      "Episode: 426, Total Reward: 71.6, Epsilon: 0.024\n",
      "Episode: 427, Total Reward: 9.899999999999999, Epsilon: 0.024\n",
      "Episode: 428, Total Reward: -4, Epsilon: 0.023\n",
      "Episode: 429, Total Reward: -5.1, Epsilon: 0.023\n",
      "Episode: 430, Total Reward: -2, Epsilon: 0.023\n",
      "Episode: 431, Total Reward: -3.5, Epsilon: 0.023\n",
      "Episode: 432, Total Reward: 4, Epsilon: 0.023\n",
      "Episode: 433, Total Reward: 3, Epsilon: 0.023\n",
      "Episode: 434, Total Reward: -10, Epsilon: 0.023\n",
      "Episode: 435, Total Reward: 6, Epsilon: 0.023\n",
      "Episode: 436, Total Reward: -6.1, Epsilon: 0.022\n",
      "Episode: 437, Total Reward: -9.1, Epsilon: 0.022\n",
      "Episode: 438, Total Reward: -4.3, Epsilon: 0.022\n",
      "Episode: 439, Total Reward: -6.2, Epsilon: 0.022\n",
      "Episode: 440, Total Reward: 1.8000000000000007, Epsilon: 0.022\n",
      "Episode: 441, Total Reward: -8, Epsilon: 0.022\n",
      "Episode: 442, Total Reward: -10, Epsilon: 0.022\n",
      "Episode: 443, Total Reward: 9.0, Epsilon: 0.022\n",
      "Episode: 444, Total Reward: 1, Epsilon: 0.022\n",
      "Episode: 445, Total Reward: -6.2, Epsilon: 0.021\n",
      "Episode: 446, Total Reward: -5.1, Epsilon: 0.021\n",
      "Episode: 447, Total Reward: -3.2, Epsilon: 0.021\n",
      "Episode: 448, Total Reward: 3.200000000000001, Epsilon: 0.021\n",
      "Episode: 449, Total Reward: 6.800000000000001, Epsilon: 0.021\n",
      "Episode: 450, Total Reward: 74.8, Epsilon: 0.021\n",
      "Episode: 451, Total Reward: 138.10000000000002, Epsilon: 0.021\n",
      "Episode: 452, Total Reward: -10, Epsilon: 0.021\n",
      "Episode: 453, Total Reward: -6, Epsilon: 0.021\n",
      "Episode: 454, Total Reward: -10, Epsilon: 0.021\n",
      "Episode: 455, Total Reward: 5, Epsilon: 0.020\n",
      "Episode: 456, Total Reward: -4.2, Epsilon: 0.020\n",
      "Episode: 457, Total Reward: 18.7, Epsilon: 0.020\n",
      "Episode: 458, Total Reward: 3.9000000000000004, Epsilon: 0.020\n",
      "Episode: 459, Total Reward: -10.1, Epsilon: 0.020\n",
      "Episode: 460, Total Reward: -10, Epsilon: 0.020\n",
      "Episode: 461, Total Reward: 63.599999999999994, Epsilon: 0.020\n",
      "Episode: 462, Total Reward: -10, Epsilon: 0.020\n",
      "Episode: 463, Total Reward: 95.19999999999999, Epsilon: 0.020\n",
      "Episode: 464, Total Reward: 25.9, Epsilon: 0.020\n",
      "Episode: 465, Total Reward: 22.4, Epsilon: 0.019\n",
      "Episode: 466, Total Reward: 4, Epsilon: 0.019\n",
      "Episode: 467, Total Reward: -2.0999999999999996, Epsilon: 0.019\n",
      "Episode: 468, Total Reward: -4.3, Epsilon: 0.019\n",
      "Episode: 469, Total Reward: 9.799999999999997, Epsilon: 0.019\n",
      "Episode: 470, Total Reward: -4.199999999999999, Epsilon: 0.019\n",
      "Episode: 471, Total Reward: -7.1, Epsilon: 0.019\n",
      "Episode: 472, Total Reward: -6.1, Epsilon: 0.019\n",
      "Episode: 473, Total Reward: 9.7, Epsilon: 0.019\n",
      "Episode: 474, Total Reward: 31.299999999999997, Epsilon: 0.019\n",
      "Episode: 475, Total Reward: 0.3000000000000007, Epsilon: 0.018\n",
      "Episode: 476, Total Reward: 2.9000000000000004, Epsilon: 0.018\n",
      "Episode: 477, Total Reward: 0.9000000000000004, Epsilon: 0.018\n",
      "Episode: 478, Total Reward: 35.5, Epsilon: 0.018\n",
      "Episode: 479, Total Reward: -10.1, Epsilon: 0.018\n",
      "Episode: 480, Total Reward: -10.1, Epsilon: 0.018\n",
      "Episode: 481, Total Reward: -10.1, Epsilon: 0.018\n",
      "Episode: 482, Total Reward: -4.1, Epsilon: 0.018\n",
      "Episode: 483, Total Reward: -2.0999999999999996, Epsilon: 0.018\n",
      "Episode: 484, Total Reward: -10.1, Epsilon: 0.018\n",
      "Episode: 485, Total Reward: -10.1, Epsilon: 0.018\n",
      "Episode: 486, Total Reward: -1.299999999999999, Epsilon: 0.018\n",
      "Episode: 487, Total Reward: 3.6000000000000014, Epsilon: 0.017\n",
      "Episode: 488, Total Reward: -2.1999999999999993, Epsilon: 0.017\n",
      "Episode: 489, Total Reward: 21.199999999999996, Epsilon: 0.017\n",
      "Episode: 490, Total Reward: -10.1, Epsilon: 0.017\n",
      "Episode: 491, Total Reward: -10.1, Epsilon: 0.017\n",
      "Episode: 492, Total Reward: -2.0999999999999996, Epsilon: 0.017\n",
      "Episode: 493, Total Reward: 77.4, Epsilon: 0.017\n",
      "Episode: 494, Total Reward: -4.1, Epsilon: 0.017\n",
      "Episode: 495, Total Reward: -3.7, Epsilon: 0.017\n",
      "Episode: 496, Total Reward: 43.099999999999994, Epsilon: 0.017\n",
      "Episode: 497, Total Reward: -3.2, Epsilon: 0.017\n",
      "Episode: 498, Total Reward: 9.799999999999997, Epsilon: 0.016\n",
      "Episode: 499, Total Reward: -7.1, Epsilon: 0.016\n",
      "Episode: 500, Total Reward: 127.70000000000002, Epsilon: 0.016\n",
      "Episode: 501, Total Reward: -10.1, Epsilon: 0.016\n",
      "Episode: 502, Total Reward: 11.700000000000003, Epsilon: 0.016\n",
      "Episode: 503, Total Reward: 16.7, Epsilon: 0.016\n",
      "Episode: 504, Total Reward: -0.5, Epsilon: 0.016\n",
      "Episode: 505, Total Reward: -2.0999999999999996, Epsilon: 0.016\n",
      "Episode: 506, Total Reward: -6.2, Epsilon: 0.016\n",
      "Episode: 507, Total Reward: 10.5, Epsilon: 0.016\n",
      "Episode: 508, Total Reward: 35.199999999999996, Epsilon: 0.016\n",
      "Episode: 509, Total Reward: -10, Epsilon: 0.016\n",
      "Episode: 510, Total Reward: -10.1, Epsilon: 0.016\n",
      "Episode: 511, Total Reward: -10, Epsilon: 0.015\n",
      "Episode: 512, Total Reward: -8.1, Epsilon: 0.015\n",
      "Episode: 513, Total Reward: 11.100000000000001, Epsilon: 0.015\n",
      "Episode: 514, Total Reward: -6.1, Epsilon: 0.015\n",
      "Episode: 515, Total Reward: -10.1, Epsilon: 0.015\n",
      "Episode: 516, Total Reward: 19.299999999999997, Epsilon: 0.015\n",
      "Episode: 517, Total Reward: -2.0999999999999996, Epsilon: 0.015\n",
      "Episode: 518, Total Reward: -7.1, Epsilon: 0.015\n",
      "Episode: 519, Total Reward: -7.1, Epsilon: 0.015\n",
      "Episode: 520, Total Reward: 189.3, Epsilon: 0.015\n",
      "Episode: 521, Total Reward: -10, Epsilon: 0.015\n",
      "Episode: 522, Total Reward: -5.199999999999999, Epsilon: 0.015\n",
      "Episode: 523, Total Reward: -6.1, Epsilon: 0.015\n",
      "Episode: 524, Total Reward: 68.5, Epsilon: 0.014\n",
      "Episode: 525, Total Reward: 11.899999999999999, Epsilon: 0.014\n",
      "Episode: 526, Total Reward: -10, Epsilon: 0.014\n",
      "Episode: 527, Total Reward: -0.09999999999999964, Epsilon: 0.014\n",
      "Episode: 528, Total Reward: 7.300000000000001, Epsilon: 0.014\n",
      "Episode: 529, Total Reward: -10, Epsilon: 0.014\n",
      "Episode: 530, Total Reward: 26.699999999999996, Epsilon: 0.014\n",
      "Episode: 531, Total Reward: 1.6000000000000014, Epsilon: 0.014\n",
      "Episode: 532, Total Reward: -1.4000000000000004, Epsilon: 0.014\n",
      "Episode: 533, Total Reward: -1.1999999999999993, Epsilon: 0.014\n",
      "Episode: 534, Total Reward: -10.1, Epsilon: 0.014\n",
      "Episode: 535, Total Reward: -1.0999999999999996, Epsilon: 0.014\n",
      "Episode: 536, Total Reward: 13.7, Epsilon: 0.014\n",
      "Episode: 537, Total Reward: 10.899999999999999, Epsilon: 0.014\n",
      "Episode: 538, Total Reward: 18.8, Epsilon: 0.013\n",
      "Episode: 539, Total Reward: -0.1999999999999993, Epsilon: 0.013\n",
      "Episode: 540, Total Reward: -10, Epsilon: 0.013\n",
      "Episode: 541, Total Reward: 1.6999999999999993, Epsilon: 0.013\n",
      "Episode: 542, Total Reward: 1.9000000000000004, Epsilon: 0.013\n",
      "Episode: 543, Total Reward: 1.8000000000000007, Epsilon: 0.013\n",
      "Episode: 544, Total Reward: -4.1, Epsilon: 0.013\n",
      "Episode: 545, Total Reward: -2.0999999999999996, Epsilon: 0.013\n",
      "Episode: 546, Total Reward: -8.1, Epsilon: 0.013\n",
      "Episode: 547, Total Reward: 6.700000000000003, Epsilon: 0.013\n",
      "Episode: 548, Total Reward: -6.1, Epsilon: 0.013\n",
      "Episode: 549, Total Reward: 5.9, Epsilon: 0.013\n",
      "Episode: 550, Total Reward: 74.9, Epsilon: 0.013\n",
      "Episode: 551, Total Reward: 22.5, Epsilon: 0.013\n",
      "Episode: 552, Total Reward: -6.1, Epsilon: 0.013\n",
      "Episode: 553, Total Reward: 15.799999999999997, Epsilon: 0.013\n",
      "Episode: 554, Total Reward: -2.1999999999999993, Epsilon: 0.012\n",
      "Episode: 555, Total Reward: -0.1999999999999993, Epsilon: 0.012\n",
      "Episode: 556, Total Reward: -8, Epsilon: 0.012\n",
      "Episode: 557, Total Reward: 0, Epsilon: 0.012\n",
      "Episode: 558, Total Reward: -4.2, Epsilon: 0.012\n",
      "Episode: 559, Total Reward: 2.8000000000000007, Epsilon: 0.012\n",
      "Episode: 560, Total Reward: -4.1, Epsilon: 0.012\n",
      "Episode: 561, Total Reward: -8.1, Epsilon: 0.012\n",
      "Episode: 562, Total Reward: 2.8000000000000007, Epsilon: 0.012\n",
      "Episode: 563, Total Reward: -5.3999999999999995, Epsilon: 0.012\n",
      "Episode: 564, Total Reward: -8.4, Epsilon: 0.012\n",
      "Episode: 565, Total Reward: -8.1, Epsilon: 0.012\n",
      "Episode: 566, Total Reward: -10.1, Epsilon: 0.012\n",
      "Episode: 567, Total Reward: -5.2, Epsilon: 0.012\n",
      "Episode: 568, Total Reward: 23.5, Epsilon: 0.012\n",
      "Episode: 569, Total Reward: -5.2, Epsilon: 0.012\n",
      "Episode: 570, Total Reward: -8.1, Epsilon: 0.011\n",
      "Episode: 571, Total Reward: 10.8, Epsilon: 0.011\n",
      "Episode: 572, Total Reward: 11.600000000000001, Epsilon: 0.011\n",
      "Episode: 573, Total Reward: -2.1999999999999993, Epsilon: 0.011\n",
      "Episode: 574, Total Reward: 7.700000000000003, Epsilon: 0.011\n",
      "Episode: 575, Total Reward: 15.700000000000003, Epsilon: 0.011\n",
      "Episode: 576, Total Reward: -0.09999999999999964, Epsilon: 0.011\n",
      "Episode: 577, Total Reward: -10, Epsilon: 0.011\n",
      "Episode: 578, Total Reward: -0.29999999999999893, Epsilon: 0.011\n",
      "Episode: 579, Total Reward: 8.8, Epsilon: 0.011\n",
      "Episode: 580, Total Reward: -4.2, Epsilon: 0.011\n",
      "Episode: 581, Total Reward: -10, Epsilon: 0.011\n",
      "Episode: 582, Total Reward: -10, Epsilon: 0.011\n",
      "Episode: 583, Total Reward: 22.799999999999997, Epsilon: 0.011\n",
      "Episode: 584, Total Reward: -2.0999999999999996, Epsilon: 0.011\n",
      "Episode: 585, Total Reward: -10.1, Epsilon: 0.011\n",
      "Episode: 586, Total Reward: 1.9000000000000004, Epsilon: 0.011\n",
      "Episode: 587, Total Reward: 23.799999999999997, Epsilon: 0.011\n",
      "Episode: 588, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 589, Total Reward: -2.0999999999999996, Epsilon: 0.010\n",
      "Episode: 590, Total Reward: 65.69999999999999, Epsilon: 0.010\n",
      "Episode: 591, Total Reward: 11.8, Epsilon: 0.010\n",
      "Episode: 592, Total Reward: 5.9, Epsilon: 0.010\n",
      "Episode: 593, Total Reward: -2.0999999999999996, Epsilon: 0.010\n",
      "Episode: 594, Total Reward: 2.8000000000000007, Epsilon: 0.010\n",
      "Episode: 595, Total Reward: 7.899999999999999, Epsilon: 0.010\n",
      "Episode: 596, Total Reward: 7.600000000000001, Epsilon: 0.010\n",
      "Episode: 597, Total Reward: 66.3, Epsilon: 0.010\n",
      "Episode: 598, Total Reward: 46.699999999999996, Epsilon: 0.010\n",
      "Episode: 599, Total Reward: 33.699999999999996, Epsilon: 0.010\n",
      "Episode: 600, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 601, Total Reward: 17.4, Epsilon: 0.010\n",
      "Episode: 602, Total Reward: -8.1, Epsilon: 0.010\n",
      "Episode: 603, Total Reward: 64.9, Epsilon: 0.010\n",
      "Episode: 604, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 605, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 606, Total Reward: 27.6, Epsilon: 0.010\n",
      "Episode: 607, Total Reward: 2.8000000000000007, Epsilon: 0.010\n",
      "Episode: 608, Total Reward: 15.399999999999999, Epsilon: 0.010\n",
      "Episode: 609, Total Reward: 1.8000000000000007, Epsilon: 0.010\n",
      "Episode: 610, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 611, Total Reward: -6.1, Epsilon: 0.010\n",
      "Episode: 612, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 613, Total Reward: -4.1, Epsilon: 0.010\n",
      "Episode: 614, Total Reward: 32.4, Epsilon: 0.010\n",
      "Episode: 615, Total Reward: 53.49999999999999, Epsilon: 0.010\n",
      "Episode: 616, Total Reward: 16.8, Epsilon: 0.010\n",
      "Episode: 617, Total Reward: 15.799999999999997, Epsilon: 0.010\n",
      "Episode: 618, Total Reward: -8.1, Epsilon: 0.010\n",
      "Episode: 619, Total Reward: -7.1, Epsilon: 0.010\n",
      "Episode: 620, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 621, Total Reward: 14.799999999999997, Epsilon: 0.010\n",
      "Episode: 622, Total Reward: -2.0999999999999996, Epsilon: 0.010\n",
      "Episode: 623, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 624, Total Reward: -2.299999999999999, Epsilon: 0.010\n",
      "Episode: 625, Total Reward: 125.4, Epsilon: 0.010\n",
      "Episode: 626, Total Reward: 9.899999999999999, Epsilon: 0.010\n",
      "Episode: 627, Total Reward: -8.1, Epsilon: 0.010\n",
      "Episode: 628, Total Reward: 8.700000000000003, Epsilon: 0.010\n",
      "Episode: 629, Total Reward: 10.700000000000003, Epsilon: 0.010\n",
      "Episode: 630, Total Reward: -2.0999999999999996, Epsilon: 0.010\n",
      "Episode: 631, Total Reward: 14.8, Epsilon: 0.010\n",
      "Episode: 632, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 633, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 634, Total Reward: -6.2, Epsilon: 0.010\n",
      "Episode: 635, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 636, Total Reward: 8.399999999999999, Epsilon: 0.010\n",
      "Episode: 637, Total Reward: -4.2, Epsilon: 0.010\n",
      "Episode: 638, Total Reward: -0.09999999999999964, Epsilon: 0.010\n",
      "Episode: 639, Total Reward: -7.300000000000001, Epsilon: 0.010\n",
      "Episode: 640, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 641, Total Reward: 2.9000000000000004, Epsilon: 0.010\n",
      "Episode: 642, Total Reward: 29.4, Epsilon: 0.010\n",
      "Episode: 643, Total Reward: 40.8, Epsilon: 0.010\n",
      "Episode: 644, Total Reward: 25.9, Epsilon: 0.010\n",
      "Episode: 645, Total Reward: -6.2, Epsilon: 0.010\n",
      "Episode: 646, Total Reward: -8.1, Epsilon: 0.010\n",
      "Episode: 647, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 648, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 649, Total Reward: -4.2, Epsilon: 0.010\n",
      "Episode: 650, Total Reward: 91.2, Epsilon: 0.010\n",
      "Episode: 651, Total Reward: -4.1, Epsilon: 0.010\n",
      "Episode: 652, Total Reward: 10.7, Epsilon: 0.010\n",
      "Episode: 653, Total Reward: -6.1, Epsilon: 0.010\n",
      "Episode: 654, Total Reward: 19.6, Epsilon: 0.010\n",
      "Episode: 655, Total Reward: 12.299999999999997, Epsilon: 0.010\n",
      "Episode: 656, Total Reward: -3.5999999999999996, Epsilon: 0.010\n",
      "Episode: 657, Total Reward: -4.4, Epsilon: 0.010\n",
      "Episode: 658, Total Reward: -0.09999999999999964, Epsilon: 0.010\n",
      "Episode: 659, Total Reward: -6.1, Epsilon: 0.010\n",
      "Episode: 660, Total Reward: -0.1999999999999993, Epsilon: 0.010\n",
      "Episode: 661, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 662, Total Reward: 11.899999999999999, Epsilon: 0.010\n",
      "Episode: 663, Total Reward: 13.5, Epsilon: 0.010\n",
      "Episode: 664, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 665, Total Reward: -6.2, Epsilon: 0.010\n",
      "Episode: 666, Total Reward: -8.2, Epsilon: 0.010\n",
      "Episode: 667, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 668, Total Reward: 14.099999999999998, Epsilon: 0.010\n",
      "Episode: 669, Total Reward: 8.399999999999999, Epsilon: 0.010\n",
      "Episode: 670, Total Reward: 4.9, Epsilon: 0.010\n",
      "Episode: 671, Total Reward: 74.10000000000001, Epsilon: 0.010\n",
      "Episode: 672, Total Reward: -2.4000000000000004, Epsilon: 0.010\n",
      "Episode: 673, Total Reward: 14.8, Epsilon: 0.010\n",
      "Episode: 674, Total Reward: -0.1999999999999993, Epsilon: 0.010\n",
      "Episode: 675, Total Reward: 8.599999999999998, Epsilon: 0.010\n",
      "Episode: 676, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 677, Total Reward: -9.3, Epsilon: 0.010\n",
      "Episode: 678, Total Reward: -4.1, Epsilon: 0.010\n",
      "Episode: 679, Total Reward: -0.09999999999999964, Epsilon: 0.010\n",
      "Episode: 680, Total Reward: -0.1999999999999993, Epsilon: 0.010\n",
      "Episode: 681, Total Reward: -6.1, Epsilon: 0.010\n",
      "Episode: 682, Total Reward: -4.3, Epsilon: 0.010\n",
      "Episode: 683, Total Reward: -0.09999999999999964, Epsilon: 0.010\n",
      "Episode: 684, Total Reward: 0.8000000000000007, Epsilon: 0.010\n",
      "Episode: 685, Total Reward: 19.799999999999997, Epsilon: 0.010\n",
      "Episode: 686, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 687, Total Reward: -8.1, Epsilon: 0.010\n",
      "Episode: 688, Total Reward: -7.1, Epsilon: 0.010\n",
      "Episode: 689, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 690, Total Reward: -2.0999999999999996, Epsilon: 0.010\n",
      "Episode: 691, Total Reward: 13.600000000000001, Epsilon: 0.010\n",
      "Episode: 692, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 693, Total Reward: -4.2, Epsilon: 0.010\n",
      "Episode: 694, Total Reward: -7.1, Epsilon: 0.010\n",
      "Episode: 695, Total Reward: 3.700000000000001, Epsilon: 0.010\n",
      "Episode: 696, Total Reward: 13.399999999999999, Epsilon: 0.010\n",
      "Episode: 697, Total Reward: -2.0999999999999996, Epsilon: 0.010\n",
      "Episode: 698, Total Reward: -6.6000000000000005, Epsilon: 0.010\n",
      "Episode: 699, Total Reward: -7.2, Epsilon: 0.010\n",
      "Episode: 700, Total Reward: 11.499999999999996, Epsilon: 0.010\n",
      "Episode: 701, Total Reward: 17.9, Epsilon: 0.010\n",
      "Episode: 702, Total Reward: 17.8, Epsilon: 0.010\n",
      "Episode: 703, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 704, Total Reward: -5.1, Epsilon: 0.010\n",
      "Episode: 705, Total Reward: 4.200000000000001, Epsilon: 0.010\n",
      "Episode: 706, Total Reward: 28.199999999999996, Epsilon: 0.010\n",
      "Episode: 707, Total Reward: -4.1, Epsilon: 0.010\n",
      "Episode: 708, Total Reward: 20.7, Epsilon: 0.010\n",
      "Episode: 709, Total Reward: 4.800000000000001, Epsilon: 0.010\n",
      "Episode: 710, Total Reward: 0.6999999999999993, Epsilon: 0.010\n",
      "Episode: 711, Total Reward: 0.9000000000000004, Epsilon: 0.010\n",
      "Episode: 712, Total Reward: -8.1, Epsilon: 0.010\n",
      "Episode: 713, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 714, Total Reward: 10.300000000000004, Epsilon: 0.010\n",
      "Episode: 715, Total Reward: 5.800000000000001, Epsilon: 0.010\n",
      "Episode: 716, Total Reward: -5.1, Epsilon: 0.010\n",
      "Episode: 717, Total Reward: -6.1, Epsilon: 0.010\n",
      "Episode: 718, Total Reward: 101.9, Epsilon: 0.010\n",
      "Episode: 719, Total Reward: 92.69999999999999, Epsilon: 0.010\n",
      "Episode: 720, Total Reward: -8.2, Epsilon: 0.010\n",
      "Episode: 721, Total Reward: 88.30000000000001, Epsilon: 0.010\n",
      "Episode: 722, Total Reward: -2.2, Epsilon: 0.010\n",
      "Episode: 723, Total Reward: 9.600000000000001, Epsilon: 0.010\n",
      "Episode: 724, Total Reward: 8.7, Epsilon: 0.010\n",
      "Episode: 725, Total Reward: -1.0999999999999996, Epsilon: 0.010\n",
      "Episode: 726, Total Reward: 3.9000000000000004, Epsilon: 0.010\n",
      "Episode: 727, Total Reward: -0.09999999999999964, Epsilon: 0.010\n",
      "Episode: 728, Total Reward: -8.1, Epsilon: 0.010\n",
      "Episode: 729, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 730, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 731, Total Reward: -6.1, Epsilon: 0.010\n",
      "Episode: 732, Total Reward: -2.0999999999999996, Epsilon: 0.010\n",
      "Episode: 733, Total Reward: 20.9, Epsilon: 0.010\n",
      "Episode: 734, Total Reward: 11.899999999999999, Epsilon: 0.010\n",
      "Episode: 735, Total Reward: -8.1, Epsilon: 0.010\n",
      "Episode: 736, Total Reward: -4.2, Epsilon: 0.010\n",
      "Episode: 737, Total Reward: -0.09999999999999964, Epsilon: 0.010\n",
      "Episode: 738, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 739, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 740, Total Reward: -6.1, Epsilon: 0.010\n",
      "Episode: 741, Total Reward: 2.9000000000000004, Epsilon: 0.010\n",
      "Episode: 742, Total Reward: 1.9000000000000004, Epsilon: 0.010\n",
      "Episode: 743, Total Reward: -4.199999999999999, Epsilon: 0.010\n",
      "Episode: 744, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 745, Total Reward: 1.8000000000000007, Epsilon: 0.010\n",
      "Episode: 746, Total Reward: 2.8000000000000007, Epsilon: 0.010\n",
      "Episode: 747, Total Reward: -3.0999999999999996, Epsilon: 0.010\n",
      "Episode: 748, Total Reward: 0.8000000000000007, Epsilon: 0.010\n",
      "Episode: 749, Total Reward: -4.1, Epsilon: 0.010\n",
      "Episode: 750, Total Reward: 56.099999999999994, Epsilon: 0.010\n",
      "Episode: 751, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 752, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 753, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 754, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 755, Total Reward: 25.700000000000003, Epsilon: 0.010\n",
      "Episode: 756, Total Reward: -7.1, Epsilon: 0.010\n",
      "Episode: 757, Total Reward: 20.9, Epsilon: 0.010\n",
      "Episode: 758, Total Reward: 10.899999999999999, Epsilon: 0.010\n",
      "Episode: 759, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 760, Total Reward: 1.5999999999999996, Epsilon: 0.010\n",
      "Episode: 761, Total Reward: -6.1, Epsilon: 0.010\n",
      "Episode: 762, Total Reward: 21.4, Epsilon: 0.010\n",
      "Episode: 763, Total Reward: -7.1, Epsilon: 0.010\n",
      "Episode: 764, Total Reward: -2.2, Epsilon: 0.010\n",
      "Episode: 765, Total Reward: -10.2, Epsilon: 0.010\n",
      "Episode: 766, Total Reward: -4.3999999999999995, Epsilon: 0.010\n",
      "Episode: 767, Total Reward: -6.1, Epsilon: 0.010\n",
      "Episode: 768, Total Reward: -0.4999999999999982, Epsilon: 0.010\n",
      "Episode: 769, Total Reward: 3.8000000000000007, Epsilon: 0.010\n",
      "Episode: 770, Total Reward: 26.6, Epsilon: 0.010\n",
      "Episode: 771, Total Reward: 8.8, Epsilon: 0.010\n",
      "Episode: 772, Total Reward: -3.3000000000000007, Epsilon: 0.010\n",
      "Episode: 773, Total Reward: -6.1, Epsilon: 0.010\n",
      "Episode: 774, Total Reward: -8.1, Epsilon: 0.010\n",
      "Episode: 775, Total Reward: -4.1, Epsilon: 0.010\n",
      "Episode: 776, Total Reward: 22.9, Epsilon: 0.010\n",
      "Episode: 777, Total Reward: 2.4000000000000004, Epsilon: 0.010\n",
      "Episode: 778, Total Reward: -10.1, Epsilon: 0.010\n",
      "Episode: 779, Total Reward: -2.0999999999999996, Epsilon: 0.010\n",
      "Episode: 780, Total Reward: 11.8, Epsilon: 0.010\n",
      "Episode: 781, Total Reward: 5.600000000000001, Epsilon: 0.010\n",
      "Episode: 782, Total Reward: 110.7, Epsilon: 0.010\n",
      "Episode: 783, Total Reward: -10, Epsilon: 0.010\n",
      "Episode: 784, Total Reward: -2.0999999999999996, Epsilon: 0.010\n",
      "Episode: 785, Total Reward: 15.8, Epsilon: 0.010\n",
      "Episode: 786, Total Reward: -6.2, Epsilon: 0.010\n",
      "Episode: 787, Total Reward: 49.3, Epsilon: 0.010\n",
      "Episode: 788, Total Reward: 19.700000000000003, Epsilon: 0.010\n",
      "Episode: 789, Total Reward: -8.1, Epsilon: 0.010\n",
      "Episode: 790, Total Reward: 17.9, Epsilon: 0.010\n",
      "Episode: 791, Total Reward: -4.1, Epsilon: 0.010\n",
      "Episode: 792, Total Reward: 6.800000000000001, Epsilon: 0.010\n",
      "Episode: 793, Total Reward: 145.8, Epsilon: 0.010\n",
      "Episode: 794, Total Reward: 3.9000000000000004, Epsilon: 0.010\n",
      "Episode: 795, Total Reward: 0.9000000000000004, Epsilon: 0.010\n",
      "Episode: 796, Total Reward: 77.9, Epsilon: 0.010\n",
      "Episode: 797, Total Reward: 1.8000000000000007, Epsilon: 0.010\n",
      "Episode: 798, Total Reward: -1.0999999999999996, Epsilon: 0.010\n",
      "Episode: 799, Total Reward: -8.1, Epsilon: 0.010\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "# 超參數設定\n",
    "BATCH_SIZE = 64\n",
    "GAMMA = 0.99\n",
    "EPSILON = 0.2\n",
    "TARGET_UPDATE = 20\n",
    "MEMORY_SIZE = 10000\n",
    "LEARNING_RATE  = 7e-5\n",
    "\n",
    "\n",
    "\n",
    "# 定義記憶重播緩衝區\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, capacity):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, state, action, reward, next_state, done):\n",
    "        self.buffer.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        batch = random.sample(self.buffer, batch_size)\n",
    "        states, actions, rewards, next_states, dones = zip(*batch)\n",
    "        return np.array(states), actions, rewards, np.array(next_states), dones\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer)\n",
    "\n",
    "# 定義環境類別\n",
    "class IntersectionEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(IntersectionEnv, self).__init__()\n",
    "        # 定義觀察空間 (4 張 84x84 圖像)\n",
    "        self.observation_space = spaces.Box(low=0, high=255, shape=(4, 84, 84), dtype=np.uint8)\n",
    "        # 定義動作空間 (5 種動作：前進、左轉、右轉、剎車、等待)\n",
    "        self.action_space = spaces.Discrete(5)\n",
    "        # 初始化環境狀態\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # 重置狀態\n",
    "        self.state = np.zeros((4, 84, 84), dtype=np.uint8)  # 模擬環境圖像\n",
    "        self.done = False\n",
    "        self.steps = 0\n",
    "        return self.state\n",
    "\n",
    "    def step(self, action):\n",
    "        # 更新狀態邏輯 (簡化版本)\n",
    "        self.steps += 1\n",
    "        reward = -0.1  # 初始懲罰降低\n",
    "\n",
    "        # 動作對應的獎勵與懲罰設計\n",
    "        if action == 0:  # 前進\n",
    "            reward = 1\n",
    "        elif action == 1:  # 左轉\n",
    "            reward = 2\n",
    "        elif action == 2:  # 右轉\n",
    "            reward = 2\n",
    "        elif action == 3:  # 剎車\n",
    "            reward = 0.5\n",
    "        elif action == 4:  # 等待\n",
    "            reward = -0.1  # 降低等待懲罰\n",
    "\n",
    "        # 增加生存獎勵和碰撞檢查\n",
    "        if self.steps > 25:\n",
    "            reward += 5\n",
    "        if random.random() < 0.1:  # 模擬碰撞\n",
    "            reward = -10\n",
    "            self.done = True\n",
    "        elif self.steps > 50:  # 超時處罰\n",
    "            self.done = True\n",
    "\n",
    "        # 更新狀態 (隨機圖像變化模擬)\n",
    "        self.state = np.random.randint(0, 255, (4, 84, 84), dtype=np.uint8)\n",
    "        return self.state, reward, self.done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass  # 可選擇用 OpenCV 或 Pygame 顯示圖像畫面\n",
    "\n",
    "    def close(self):\n",
    "        pass\n",
    "\n",
    "# 定義 DRQN 模型\n",
    "class DRQN(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DRQN, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(4, 32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.lstm = nn.LSTM(64 * 7 * 7, 512, batch_first=True)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = x / 255.0  # 標準化影像輸入\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x, hidden = self.lstm(x.unsqueeze(0), hidden)\n",
    "        x = self.fc(x.squeeze(0))\n",
    "        return x, hidden\n",
    "\n",
    "# 環境與模型初始化\n",
    "env = IntersectionEnv()\n",
    "n_actions = env.action_space.n\n",
    "input_shape = (4, 84, 84)\n",
    "policy_net = DRQN(input_shape, n_actions)\n",
    "target_net = DRQN(input_shape, n_actions)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.Adam(policy_net.parameters(), lr=LEARNING_RATE)\n",
    "memory = ReplayBuffer(MEMORY_SIZE)\n",
    "\n",
    "best_reward = float('-inf')  # 初始化最佳獎勵\n",
    "\n",
    "# 訓練過程\n",
    "for episode in range(800):\n",
    "    state = env.reset()\n",
    "    hidden = (torch.zeros(1, 1, 512), torch.zeros(1, 1, 512))  # 初始化 LSTM 隱藏狀態\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    epsilon = max(0.01, EPSILON * (0.995 ** episode))  # 動態 ε 更新\n",
    "\n",
    "    while not done:\n",
    "        # 探索與利用策略選擇動作\n",
    "        if random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state_tensor = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "                q_values, hidden = policy_net(state_tensor, hidden)\n",
    "                action = q_values.max(1)[1].item()\n",
    "\n",
    "        # 執行動作並存入記憶池\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        memory.push(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "        # 訓練模型\n",
    "        if len(memory) > BATCH_SIZE:\n",
    "            batch = memory.sample(BATCH_SIZE)\n",
    "            states, actions, rewards, next_states, dones = batch\n",
    "\n",
    "            states = torch.tensor(states, dtype=torch.float32)\n",
    "            actions = torch.tensor(actions, dtype=torch.int64).unsqueeze(1)\n",
    "            rewards = torch.tensor(rewards, dtype=torch.float32)\n",
    "            next_states = torch.tensor(next_states, dtype=torch.float32)\n",
    "            dones = torch.tensor(dones, dtype=torch.float32)\n",
    "\n",
    "            q_values, _ = policy_net(states, hidden)\n",
    "            q_values = q_values.gather(1, actions).squeeze(1)\n",
    "\n",
    "            next_q_values, _ = target_net(next_states, hidden)\n",
    "            expected_q_values = rewards + GAMMA * next_q_values.max(1)[0] * (1 - dones)\n",
    "\n",
    "            loss = nn.MSELoss()(q_values, expected_q_values.detach())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # 更新最佳模型\n",
    "    if total_reward > best_reward:\n",
    "        best_reward = total_reward\n",
    "        torch.save(policy_net.state_dict(), 'DRQN2.pth')\n",
    "\n",
    "    # 定期更新目標網絡\n",
    "    if episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "    print(f\"Episode: {episode}, Total Reward: {total_reward}, Epsilon: {epsilon:.3f}\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\EE715\\anaconda3\\envs\\highway_env\\lib\\site-packages\\gymnasium\\envs\\registration.py:517: DeprecationWarning: \u001b[33mWARN: The environment intersection-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.deprecation(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "Episode: 1, Total Reward: 9.0\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "Episode: 2, Total Reward: 9.0\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "Episode: 3, Total Reward: 10.0\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "Episode: 4, Total Reward: -1.0\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "Episode: 5, Total Reward: 9.0\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "Episode: 6, Total Reward: 10.0\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "Episode: 7, Total Reward: 0.0\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "Episode: 8, Total Reward: 0.0\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "Episode: 9, Total Reward: -1.0\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "State shape: torch.Size([1, 4, 84, 84])\n",
      "Episode: 10, Total Reward: -1.8408397203722444\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import highway_env\n",
    "\n",
    "# 測試參數設定\n",
    "MODEL_PATH = 'DRQN2.pth'\n",
    "\n",
    "# 加載HighwayEnv環境\n",
    "env = gym.make('intersection-v0', render_mode='human')\n",
    "\n",
    "# 模型定義\n",
    "class DRQN(torch.nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(DRQN, self).__init__()\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(4, 32, kernel_size=8, stride=4),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=4, stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(64, 64, kernel_size=3, stride=1),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.lstm = torch.nn.LSTM(64 * 7 * 7, 512, batch_first=True)\n",
    "        self.fc = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = x / 255.0\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x, hidden = self.lstm(x.unsqueeze(0), hidden)\n",
    "        x = self.fc(x.squeeze(0))\n",
    "        return x, hidden\n",
    "\n",
    "# 加載訓練好的模型\n",
    "input_shape = (4, 84, 84)\n",
    "n_actions = 5\n",
    "policy_net = DRQN(input_shape, n_actions)\n",
    "policy_net.load_state_dict(torch.load(MODEL_PATH))\n",
    "policy_net.eval()\n",
    "\n",
    "# 測試模型 (至少跑 3 次)\n",
    "episodes = 10\n",
    "for episode in range(episodes):\n",
    "    state, _ = env.reset()\n",
    "    hidden = (torch.zeros(1, 1, 512), torch.zeros(1, 1, 512))  # 初始化隱藏狀態\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        with torch.no_grad():\n",
    "            # 確保狀態大小正確\n",
    "            if len(state.shape) != 3 or state.shape[0] == 0 or state.shape[1] == 0:\n",
    "                state = np.zeros((4, 84, 84), dtype=np.float32)  # 默認大小 (4, 84, 84)\n",
    "            else:\n",
    "                if len(state.shape) == 3:  # 確保是 (C, H, W)\n",
    "                    state = np.transpose(state, (2, 0, 1))  # (C, H, W)\n",
    "\n",
    "                # 如果通道數不是4，補充或複製通道\n",
    "                if state.shape[0] != 4:\n",
    "                    state = np.repeat(state, 4 // state.shape[0], axis=0)\n",
    "\n",
    "            # 最後轉換為 Tensor\n",
    "            state = torch.tensor(state, dtype=torch.float32).unsqueeze(0)  # 增加批次維度\n",
    "            print(f\"State shape: {state.shape}\")  # 調試輸出狀態大小\n",
    "\n",
    "            # 更新隱藏狀態\n",
    "            hidden = (hidden[0].detach(), hidden[1].detach())\n",
    "\n",
    "            # 模型預測動作\n",
    "            q_values, hidden = policy_net(state, hidden)\n",
    "            action = q_values.max(1)[1].item()\n",
    "\n",
    "        # 執行動作\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "\n",
    "        # 更新狀態\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "\n",
    "    print(f\"Episode: {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "highway_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
